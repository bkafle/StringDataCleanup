{
 "metadata": {
  "name": "Bond_CusipMerge"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Import all related modules\nimport datetime\nimport csv\nimport string\nimport os\nimport re\nimport pandas as pd \nimport sys \nfrom pandas import DataFrame, read_csv\n\n### displaying the time of start\nstarttime = datetime.datetime.now()\nprint \"Process Start Time: %s\" %starttime",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Process Start Time: 2016-05-25 15:37:07.761000\n"
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "### checking working directory and setting appropriately\nos.getcwd()\nos.chdir(r'C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy')## this should be the path where you would like to work",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# DISPLAY PYTHON VERSION\nprint('Python version: '+ sys.version)\nprint ('Pandas version: '+pd.__version__)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Python version: 2.7.6 |Anaconda 1.9.1 (64-bit)| (default, Nov 11 2013, 10:49:15) [MSC v.1500 64 bit (AMD64)]\nPandas version: 0.13.1\n"
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df_creation_start = datetime.datetime.now()\n# to read the CSV file as Dataframe in pandas\nLocation = r'Jesse_Project/Bond_Raw.csv'\ndfB = pd.read_csv(Location,sep=',',error_bad_lines = False, index_col = False, dtype = 'unicode')\n\nend_df_creation_time = datetime.datetime.now()\ndf_tt = end_df_creation_time-df_creation_start\nprint \"Timetaken to create Dataframe from original file: %s\" %(df_tt)\n### Testing Below code for counting records verifies DF has been created",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Timetaken to create Dataframe from original file: 0:07:30.110000\n"
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## counting the number of rows and columns in file\nCount_Row=dfB.shape[0] #gives number of row count\nprint \"Number of rows/lines in original file: %s\"%Count_Row\nCount_Col=dfB.shape[1] #gives number of col count\nprint \"Number of columns in original file: %s\"%Count_Col",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Number of rows/lines in original file: 7941576\nNumber of columns in original file: 80\n"
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\ncopytime = datetime.datetime.now()\n## Select the attributes you would need for analyzing the data\n## this will make the file size smaller and processing will be much faster especially\n## if there are too many unrequired attributes in source data\n\nRCS_DF_B = dfB[['Fundid','cusip','security','maturity','coupon','cusip8']]\n\n## Download file as CSV with only few columns from Dataframe\nRCS_DF_B.to_csv('Jesse_Project/Bond_somecols.csv',index=False,header = True)\n\n\nendcp_time = datetime.datetime.now()\ncc_tt = endcp_time-copytime\nprint \"Timetaken to copy: %s\" %(cc_tt)\n## Testing - Validate the file is created and present in the location assigned",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Timetaken to copy: 0:00:26.633000\n"
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# This code takes a csv input file and reads line by line.\n# It adds five new columns based on columns in input file, and writes a new file with added columns\n# Added Column 1 - 'RCS_CUSIP6' - fills with CUSIP present in input file\n# Added Column 2 - 'RCS_CUSIP8' - fills with CUSIP8 present in input file\n# Added Column 3 - 'RCS_COUPON' - fills with COUPON from security if COUPON is not present in input file\n# ADded Column 4 -  'RCS_DATE' - fills with MATURITY_DATE from secrity if MATURITY_DATE is not present in input file\n# Added Column 5 - 'RCS_SECURITY' - this is the stripped SECURITY without number and date on it\n\n\"\"\"\n****************************************************************************\nThe below code with filter Number and Date as below\na) If data = 'RCS 10/12/2016 7.5% ya' then RCS_SECURITY = 'RCS YA'; RCS_MATURITY = '10/12/2016';RCS_COUPON = '7.5%'\nb) if data = 'RCS YAHO 20101212 768' then RCS_SECURITY = 'RCS YAHO';RCS_MATURITY = '12/12/2010'\nc) if data = '679 YAHO 5477.32 RCS' then RCS_SECURITY = 'YAHO 5477.32 RCS'\n\n*****************************************************************************\n\"\"\"\n## Display Starttime\nimport datetime\nstarttime_clean = datetime.datetime.now()\nprint \"Process Start Time: %s\" %starttime_clean\n\n## importing library for reading CSV file \nimport csv\nimport re  ## for Regular Expression\n\nwith open('Jesse_Project/Bond_somecols.csv', 'r') as infile:  \n     with open('Jesse_Project/Bond_RCS_Cols.csv', 'wb') as outfile:\n         reader = csv.reader(infile, delimiter=',')\n         writer = csv.writer(outfile, delimiter=',')\n         \n            \n         next(infile,None)## skip the old header\n            \n         ## write new header as below\n         writer.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON','RCS_MATURITY','RCS_CUSIP6','RCS_CUSIP8','CUSIP',\n                'SECURITY','MATURITY','COUPON','CUSIP8'])\n         \n         ## process a row at a time line by line   \n         for row in reader:\n                \n                rcs_cusip6 = row[1] # adding rcs_cusip6 a new column same as present in input file for now\n                rcs_cusip8 = row[5] # adding rcsS_cusip8 a new column same as present in input file for now\n                \n                ## related to extracting Security after removing numbers and date\n                rcs_security_rstrip = row[2].rstrip('$+#?*@-0123456789.,%/ )( ') # removing trailing numbers and date from right side\n                rcs_security_lstrip = rcs_security_rstrip.lstrip('$+#?*@-0123456789.,%/ )( ') # strip left side as well \n                rcs_security = rcs_security_lstrip.upper() ## convert security into UpperCase so that it's easy for comparison\n                \n                \n                ## related to extracting coupon\n                #if row[4] is not None and row[4]  '0': # if coupon is present populate it as RCS_COUPON\n                #    rcs_coupon = row[4]  ## populates  coupon from what is in coupon as it is correct \n                    \n                if '%' in row[2]: ## if coupon is not present and security has % then\n                    rcs_coupon1 = re.findall(r\"[-+]?\\d*\\.[0-9]+%|[0-9]+%\",row[2])\n                    if not rcs_coupon1:\n                        rcs_coupon = \" \".join(str(c) for c in rcs_coupon1)\n                    else:\n                        rcs_coupon = str(rcs_coupon1[0])  \n                        rcs_coupon = rcs_coupon.rstrip('% ')  ## removing % from coupon to have only number\n                                            \n                else:\n                    rcs_coupon = row[4]  ## populates coupon with exiting values  if above conditions don't match\n                              \n                ## this part will populate MATRUITY DATE if already not present and present in Security\n                if '/' in row[3] or  '-' in row[3]:  \n                    rcs_date = row[3]\n                    \n                else:          \n                    if '/' in row[2]:\n                        \n                        d = re.findall('(\\d+[/]\\d+[/]\\d+)',row[2])\n                        if not d:\n                            rcs_date = \" \".join(str(c) for c in d)\n                        else:\n                        ## handling dates in different format and converting to mm/dd/yyyy format\n                            date = str(d[0])\n                            try:\n                                rcs_date = datetime.datetime.strptime(date,'%m-%d-%y').strftime('%m/%d/%Y')\n                            except:\n                                try:\n                                    rcs_date = datetime.datetime.strptime(date,'%y-%m-%d').strftime('%m/%d/%Y')\n                                except:\n                                    rcs_date = date\n                        \n                    elif '-' in row[2]:\n                        d = re.findall('(\\d+[-]\\d+[-]\\d+)',row[2])\n                        if not d:\n                            rcs_date = \" \".join(str(c) for c in d)\n                        else:\n                            date = str(d[0])\n                        \n                            try:\n                                rcs_date = datetime.datetime.strptime(date,'%m-%d-%Y').strftime('%m/%d/%Y')\n                            except:\n                                try:\n                                    rcs_date = datetime.datetime.strptime(date,'%Y-%m-%d').strftime('%m/%d/%Y')\n                                except:\n                                    rcs_date = date\n                    #elif '.' in s\n                    else:\n                        d = re.findall('(\\d{4}\\d{2}\\d{2})',row[2])\n                        if not d:\n                            rcs_date = \" \".join(str(c) for c in d)\n                        else:\n                            date = str(d[0])\n                            try:\n                                rcs_date = datetime.datetime.strptime(date,'%Y%m%d').strftime('%m/%d/%Y')\n                            except:\n                                try:\n                                    rcs_date = datetime.datetime.strptime(date,'%m%d%Y').strftime('%m/%d/%Y')\n                                except:\n                                    rcs_date = date\n                  \n                \n                      \n                \n                writer.writerow([row[0],rcs_security,rcs_coupon,rcs_date,rcs_cusip6,rcs_cusip8] +row[1:])\n\n                \n # Display the endtime after program is completed\nendtime_clean = datetime.datetime.now()\nprint \"Process Ended: %s\" %endtime_clean\n\n## Display the time taken to run the job\nclean_tt = endtime_clean - starttime_clean\nprint \"Timetaken to process cleaning up data: %s\" %clean_tt\n\"\"\"\n****************************************************************************\nAfter the code has been executed\na) There will be no leading/trailing numbers or special characters\nb) No number followed by % will be present in RCS_SECURITY\nc) Date in any format if not originally populated and present in string will be populated in mm/dd/yyyy\n\n*****************************************************************************\n\"\"\"\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Process Start Time: 2016-05-25 15:38:23.216000\nProcess Ended: 2016-05-25 15:40:28.632000"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nTimetaken to process cleaning up data: 0:02:05.416000\n"
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": "'\\n****************************************************************************\\nAfter the code has been executed\\na) There will be no leading/trailing numbers or special characters\\nb) No number followed by % will be present in RCS_SECURITY\\nc) Date in any format if not originally populated and present in string will be populated in mm/dd/yyyy\\n\\n*****************************************************************************\\n'"
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "starttime_dedup = datetime.datetime.now()\nprint \"Process Start Time for De-duplication: %s\" %starttime_dedup\n\n## this piece of code will de-dup the records based on 'RCS_SECURITY' field\nimport pandas as pd\nfilein= r'Jesse_Project/Bond_RCS_Cols.csv'\ntoclean = pd.read_csv(filein,sep=',',error_bad_lines = False, index_col = False, dtype = 'unicode')\ndeduped = toclean.drop_duplicates(['RCS_SECURITY'])\n\n\n## sort the file on RCS_SECURITY in ascending order\nSorted = deduped.sort(['RCS_SECURITY'],ascending = True)\n\n##exporting the Dataframe to csv file \nSorted.to_csv('Jesse_Project/Bond_Sorted.csv',index=False,header = True)\n\n## counting the number of rows for deduped file\nCount_Row_deduped=deduped.shape[0] #gives number of row count\nprint \"Number of rows/lines in original file: %s\"%Count_Row_deduped\n\n\nend_time_dedup = datetime.datetime.now()\nprint \"Process Ended for Deduplication: %s\" %end_time_dedup\n\ndedup_tt = end_time_dedup - starttime_dedup\nprint \"Timetaken to for dedup process: %s\" %(dedup_tt)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Process Start Time for De-duplication: 2016-05-25 16:03:08.352000\nNumber of rows/lines in original file: 136614"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nProcess Ended for Deduplication: 2016-05-25 16:06:12.095000\nTimetaken to for dedup process: 0:03:03.743000\n"
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\nimport csv\n\nst_remove_der= datetime.datetime.now()\nprint \"Process Start Time for removing Derivatives: %s\" %st_remove_der\n\nderivatives=[\"derivative\", \"put\", \"put@\", \"put\", \"-put\", \"usd p\", \"usd rec\",\n\"call\",\" call@\", \"cll\", \"-call\", \"usd c\", \"buy\", \n\"optn\", \"option\", \"libor\", \"euroibor\", \"euroyen\", \"eurodollar\",\n\"forward\", \"fwd\", \"(fwd)\", \"cmdtyfut\", \"rtp\", \"rtr\", \"interest rate fut\",\n\"future\", \"futures\", \"fut\", \"(fut)\", \" futr\", \"ftr\", \"ftrs\", \n\"swap\", \"swap:\", \"swp:\", \"swaption\", \"swp\", \"swp:\", \"swap\", \"swap\", \"swpn\", \"swptn\", \"swptn\", \n\"ccs\", \"irs\", \"iswp\", \"irs:\", \"trs\", \"trs:\", \"trswap\", \"trswap:\",\n\"cds\", \"cds\", \"cds:\", \"cds(\", \"cds-\", \"cds\", \"iro\", \"otc\", \n\"designated currency contract\", \"american style\", \"strike price\", \"str\", \"expire\", \"sold credit\", \n\"receive a fixed rate\", \"recevie a fixed rate\", \"pay\", \"payb\", \"fswp\", \"fswp\", \"fswp\"]\n\n\n\n# the files\ninfile = \"Jesse_Project/Bond_Sorted.csv\"\noutfile = \"Jesse_Project/Bond_NoDeri_Security.csv\"\nderifile = \"Jesse_Project/Bond_Derivatives_Security.csv\"\n\n# changing the case of words in derviates to Upper since our data is Upper\nde = set(word.upper() for word in derivatives)\n\n\nwith open(infile, 'rb') as inFile, open(derifile,'wb') as dFile, open(outfile, 'wb') as outFile:\n    reader = csv.reader(inFile, delimiter=',')\n    writer = csv.writer(outFile, delimiter=',')\n    writer1 = csv.writer(dFile, delimiter=',')\n    for row in reader:\n        readrow = re.split(\"[@_()-: ]+\",row[1])\n        if not set(readrow) & set(de):\n            writer.writerow(row) \n        else:\n            writer1.writerow(row)\n\n            \n### Code to diplay the rowcount in File created for further Processing and finding Cusip ie Bond_NoDeri_Security\nwith open(\"Jesse_Project/Bond_NoDeri_Security.csv\",\"rb\") as f:\n    reader = csv.reader(f,delimiter = \",\")\n    data = list(reader)\n    row_count = len(data)\nprint \"Number of rows present for NoDerivatives: %s\"%row_count\n\n\n\n### Time display and timetaken information\net_remove_der = datetime.datetime.now()\nprint \"Process Ended for Sorting: %s\" %et_remove_der\n\nremove_tt = et_remove_der - st_remove_der\nprint \"Timetaken to for sorting process: %s\" %(remove_tt)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Process Start Time for removing Derivatives: 2016-05-25 16:07:23.734000\nNumber of rows present for NoDerivatives: 134124"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nProcess Ended for Sorting: 2016-05-25 16:07:29.586000\nTimetaken to for sorting process: 0:00:05.852000\n"
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## This takes the Security file and abbreviates any string according to cusip_abbreviations.csv\n##if a string whose abbreviated form is present then it abbreviates\n##  For example  AAMES MORTGAGE TRUST -----> AAMES MTG TR\nimport csv\nimport re\nimport string\n# Create Dictionary structure of cusip_abbreviations.csv file \nwith open(\"Jesse_Project/cusip_abbreviations.csv\", \"rb\") as fp1:\n    dic_file2 = csv.reader(fp1,)\n    dict2 = {}\n    for a in dic_file2:\n        a[1] = re.sub('[^A-Za-z0-9)]+','',a[1])\n        a[2] = re.sub('[^A-Za-z0-9)]+','',a[2])\n        dict2[a[2]] = a[1]\n\n            \nwith open(\"Jesse_Project/Bond_Abbreviated.csv\", \"wb\") as fw1:\n    with open(\"Jesse_Project/Bond_NoDeri_Security.csv\", \"r\") as fr1:\n        output = csv.writer(fw1, delimiter=\",\")\n        writer1 = csv.writer(fw2,delimiter = \",\")\n        read = csv.reader(fr1,)\n            \n        next(fr1, None)\n            \n        output.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8']) \n           \n        for row in read:\n            row_split = row[1].split()\n            abb_ = False\n            new_row = row[1]\n            for s in row_split:\n                s = re.sub('[^A-Za-z0-9)]+','',s)\n                for di in dict2:\n                    if di == s:\n                        new_row = string.replace(new_row,s,dict2[di])\n                        abb_ = True\n            if abb_:\n                row[1] = re.sub('[^A-Za-z0-9 )]+','',new_row)# remove any special characters from string\n                output.writerow(row)\n            else:\n                row[1] = re.sub('[^A-Za-z0-9 )]+','',row[1]) # remove any special characters from string\n                output.writerow(row)\n\n\n### Testing - Verify word with 'MORTGAGE' is not present in RCS_SECURITY, instead should be MTG.",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## This code is in preparation for the code down.\n## This will dedup the original file-MasterCusip file so that it is relatively\n## faster for processing the Merge\nimport pandas as pd\n\n## reading the file\nfile_cusip = r'Jesse_Project/WORK_CONSOLIDATED_CUSIPS.csv'\n\n## creating a DF\ntoclean_cusip = pd.read_csv(file_cusip,sep=',',error_bad_lines = False, index_col = False, dtype = 'unicode')\ndeduped = toclean_cusip.drop_duplicates(['Alpha Description 1'])## removing duplicates\n\n## sort the file in ascending order\nSorted_cusip = deduped.sort(['CUSIP Issuer Number'],ascending = True)\n\n##Counting the number or records in the file\nCount_Row_cusip=Sorted_cusip.shape[0] #gives number of row count\nprint \"Number of rows/lines in Cusipfile: %s\"%Count_Row_cusip\n\n\n##exporting the Dataframe to csv file \nSorted_cusip.to_csv('Jesse_Project/MasterCusip_Deduped.csv',index=False,header = True)\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## This code takes the cleaned version after fixing abbreviations and goes for Merging with CUSIP\n## This doesn't into consideration about CUSIP value originally present in Data from previous process\n## This code produces two files - Merged and NoMerge files\n## File1 -- Merged.csv has all the Security with CUSIP6 populated after the lookup with CUSIP file\n## File2 -- NoMerge.csv has all the Security whose CUSIP6 wasn't present in lookup with CUSIP file\nimport csv\nimport re\n# Create Dictionary structure for CUSIP_MASTER file\nwith open(\"Jesse_Project/MasterCusip_Deduped.csv\", \"rb\") as fp:\n    dic_file = csv.reader(fp,)\n    dict1 = {}\n    for d in dic_file:\n        d[1] = re.sub('[^A-Za-z0-9)]+','',d[1])\n        dict1[d[1]] = d[0]\n\n\nwith open(\"Jesse_Project/Bond_Merged.csv\", \"wb\") as fw1:\n    with open(\"Jesse_Project/Bond_Abbreviated.csv\", \"r\") as fr1:\n        with open(\"Jesse_Project/Bond_NoMerge.csv\", \"wb\") as fw2:\n            output = csv.writer(fw1, delimiter=\",\")\n            writer1 = csv.writer(fw2,delimiter=\",\")\n            read = csv.reader(fr1,)\n            \n            next(fr1, None)\n            \n            output.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','MATCH TYPE','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8'])\n            \n            writer1.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8']) \n            \n            for row in read:\n                row_c = re.sub('[^A-Za-z0-9)]+','',row[1])\n                strip_20first = row_c[:20]\n                strip_18first = row_c[:18]\n                strip_16first = row_c[:16]\n                strip_14first = row_c[:14]\n                strip_12first = row_c[:12]\n              \n                \n                found_ = False\n                for d in dict1:\n                    \n                    if d == row_c:     \n                        row[4] = dict1[d]\n                        flag = 'Exact Match'\n                        found_ = True\n                    \n                    elif d[:20] == strip_20first:\n                        row[4] = dict1[d]\n                        flag = 'First20_Match'\n                        found_ = True\n                    \n                    elif d[:18] == strip_18first:\n                        row[4] = dict1[d]\n                        flag = 'First18_Match'\n                        found_ = True\n                    \n                    elif d[:16] == strip_16first:\n                        row[4] = dict1[d]\n                        flag = 'First16_Match'\n                        found_ = True\n                        \n                    elif d[:14] == strip_14first:\n                        row[4] = dict1[d]\n                        flag = 'First14_Match'\n                        found_ = True\n                        \n                    elif d[:12] == strip_12first:\n                        row[4] = dict1[d]\n                        flag = 'First12_Match'\n                        found_ = True  \n                    else:\n                        pass\n                    \n                    \n                if found_:    \n                    output.writerow([row[0],row[1],row[2],row[3],row[4],flag]+row[5:]) ## write only the matching ones\n                else: \n                    writer1.writerow(row)\n\n## row count in each file\nwith open(\"Jesse_Project/Bond_Merged.csv\",\"rb\") as fm, open(\"Jesse_Project/Bond_NoMerge.csv\",\"rb\") as fNm:\n    fm = csv.reader(fm,delimiter = \",\")\n    fNm = csv.reader(fNm,delimiter = \",\")\n    data_fm = list(fm)\n    row_merged = len(data_fm)\n    data_fNm = list(fNm)\n    row_notmerged = len(data_fNm)\nprint \"Number of rows present for in MergedFile: %s\"%row_merged\nprint \"Number of rows present for in NoMerge: %s\"%row_notmerged",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## This code takes the cleaned version after fixing abbreviations and goes for Merging with CUSIP\n## This code takes into consideration of CUSIP values that were present from previous process\n## This code produces two files - Merged and NoMerge files\n## File -- CodeB_Merged.csv has all the Security with CUSIP6 populated after the lookup with CUSIP file\n## File -- Bond_NoMerge.csv has all the Security whose CUSIP6 wasn't present in lookup with CUSIP file\n## In this if Exact Match for security is not found then it will check if CUSIP value is already present originally in RAW file\n## if CUSIP value is present and if that CUSIP value exist in 'MasterCusip' file then keep that value\n## Then it will go and do a 'First N Character' Match\nimport csv\nimport re\n# Create Dictionary structure for CUSIP_MASTER file\nwith open(\"Jesse_Project/MasterCusip_Deduped.csv\", \"rb\") as fp:\n    dic_file = csv.reader(fp,)\n    dict1 = {}\n    for d in dic_file:\n        d[1] = re.sub('[^A-Za-z0-9)]+','',d[1])\n        dict1[d[1]] = d[0]\n\n\nwith open(\"Jesse_Project/Bond_Merged_RAWCusip.csv\", \"wb\") as fw1:\n    with open(\"Jesse_Project/Bond_Abbreviated.csv\", \"r\") as fr1:\n        with open(\"Jesse_Project/Bond_NoMerge_RAWCusip.csv\", \"wb\") as fw2:\n            output = csv.writer(fw1, delimiter=\",\")\n            writer1 = csv.writer(fw2,delimiter=\",\")\n            read = csv.reader(fr1,)\n            \n            next(fr1, None)\n            \n            output.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','MATCH TYPE','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8'])\n            \n            writer1.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8']) \n            \n            for row in read:\n                row_c = re.sub('[^A-Za-z0-9)]+','',row[1])\n                strip_20first = row_c[:20]\n                strip_18first = row_c[:18]\n                strip_16first = row_c[:16]\n                strip_14first = row_c[:14]\n                strip_12first = row_c[:12]\n                \n\n                \n                found_ = False\n                for d in dict1:\n                    \n                    if d == row_c:     \n                        row[4] = dict1[d]\n                        flag = 'Exact Match'\n                        found_ = True\n                    \n                    elif dict1[d] == row[4][:-3]:\n                        row[4] = dict1[d]\n                        flag = 'RAW Value Match'## value that was in RAW data originally\n                        found_ = True\n                        \n                    \n                    elif d[:20] == strip_20first:\n                        row[4] = dict1[d]\n                        flag = 'First20_Match'\n                        found_ = True\n                    \n                    elif d[:18] == strip_18first:\n                        row[4] = dict1[d]\n                        flag = 'First18_Match'\n                        found_ = True\n                    \n                    elif d[:16] == strip_16first:\n                        row[4] = dict1[d]\n                        flag = 'First16_Match'\n                        found_ = True\n                        \n                    elif d[:14] == strip_14first:\n                        row[4] = dict1[d]\n                        flag = 'First14_Match'\n                        found_ = True\n                        \n                    elif d[:12] == strip_12first:\n                        row[4] = dict1[d]\n                        flag = 'First12_Match'\n                        found_ = True\n                    else:\n                        pass\n                    \n                    \n                if found_:    \n                    output.writerow([row[0],row[1],row[2],row[3],row[4],flag]+row[5:]) ## write only the matching ones\n                else: \n                    writer1.writerow(row)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## This code takes the cleaned version after fixing abbreviations and goes for Merging with CUSIP\n## \n## File -- Bond_Merged_MultipleCusip.csv has all the Security with CUSIP6 populated after the lookup,and if multiple \n##             distinct CUSIP6 is found for firstN character all those CUSIP6 will be populated\n## In this code didn't write the Non-matching to a separate file as it was already done with previous code and\n##            would give the same result/file for NonMerged records\nimport csv\nimport re\n# Create Dictionary structure for CUSIP_MASTER file\nwith open(\"C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy/Final/CONSOLIDATED_CUSIPS_NODUPS.csv\", \"rb\") as fp:\n    dic_file = csv.reader(fp,)\n    dict1 = {}\n    for d in dic_file:\n        d[1] = re.sub('[^A-Za-z0-9)]+','',d[1])\n        dict1[d[1]] = d[0]\n\n\nwith open(\"C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy/Final/Bond_Merged_MultipleCusip.csv\", \"wb\") as fw1:\n    with open(\"C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy/Final/Abbreviated.csv\", \"r\") as fr1:\n        output = csv.writer(fw1, delimiter=\",\")\n        writer1 = csv.writer(fw2,delimiter=\",\")\n        read = csv.reader(fr1,)\n            \n        next(fr1, None)\n            \n        output.writerow(['FUNDID','RCS_SECURITY','RCS_COUPON',\n                        'RCS_MATURITY','RCS_CUSIP6','MATCH TYPE','RCS_CUSIP8',\n                'CUSIP','SECURITY','MATURITY','COUPON','CUSIP8'])\n            \n        for row in read:\n            row_c = re.sub('[^A-Za-z0-9)]+','',row[1])\n            strip_20first = row_c[:20]\n            strip_18first = row_c[:18]\n            strip_16first = row_c[:16]\n            strip_14first = row_c[:14]\n            strip_12first = row_c[:12]\n\n                \n            found_ = False\n            match = []\n            for d in dict1:\n                if d == row_c:     \n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'Exact Match'\n                    found_ = True\n                    continue\n                    \n                    \n                elif dict1[d] == row[4][:-3]:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'RAW Value'## value that was in RAW data originally\n                    found_ = True\n                    continue\n                        \n                    \n                elif d[:20] == strip_20first:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'First20_Match'\n                    found_ = True\n                    continue\n                    \n                    \n                elif d[:18] == strip_18first:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'First18_Match'\n                    found_ = True\n                    continue\n                    \n                    \n                elif d[:16] == strip_16first:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'First16_Match'\n                    found_ = True\n                    continue\n                     \n                        \n                elif d[:14] == strip_14first:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'First14_Match'\n                    found_ = True\n                    continue\n                        \n                elif d[:12] == strip_12first:\n                    if dict1[d] not in match:\n                        match.append(dict1[d])\n                    flag = 'First12_Match'\n                    found_ = True\n                    continue\n                        \n                else:\n                    pass\n                    \n            row[4] = \",\".join(match)    \n            if found_:    \n                output.writerow([row[0],row[1],row[2],row[3],row[4],flag]+row[5:]) ## write only the matching ones\n            ",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "## this code formats the date of MasterCusip to align with the MaturityDate present in DataFile\n## this code was written to see if maturity date and Coupon in MasterCusip might come in handy for secondary lookups\nimport csv\nimport os\nimport datetime\n\nstarttime_df = datetime.datetime.now()\nprint \"Process Start Time: %s\" %starttime_df\n\ninputfile = ('C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy/Master_Cusip_NoDups.csv')\noutputfile = ('C:/Users/bkafle/Desktop/bir_fuzzy_wuzzy/Master_Cusip_Dateformat.csv')\n\nwith open(inputfile, 'rb') as inFile, open(outputfile, 'wb') as outfile:\n    r = csv.reader(inFile)\n    w = csv.writer(outfile)\n    \n    # process the date and copy into a new file\n    for row in r:\n        if row[6] != \" \":\n            try:\n                rcs_date = datetime.datetime.strptime(row[6],'%Y%m%d').strftime('%m/%d/%Y')\n            except:\n                rcs_date = row[6]\n        else:\n            rcs_date = row[6]\n                \n        row[6] = rcs_date\n        w.writerow(row)\n\n\nend_time_dtformat = datetime.datetime.now()\nprint \"Process Ended: %s\" %(end_time_dtformat - starttime_df)",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}